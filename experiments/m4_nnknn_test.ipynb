{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdf85d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from utils import clean_daily_series, build_windows, rmse, mae, smape, mase, directional_accuracy, print_evaluation_table\n",
    "from pathlib import Path\n",
    "import importlib.util\n",
    "\n",
    "module_path = Path.cwd().resolve() / \"..\" /\"src\" / \"nnknn\" / \"nnknn.py\"\n",
    "spec = importlib.util.spec_from_file_location(\"nnknn\", str(module_path))\n",
    "mod = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(mod)\n",
    "NNKNN = mod.NNKNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "355b6a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_train = pd.read_csv('../src/data/m4_forecasting/Daily-train.csv')\n",
    "daily_test = pd.read_csv('../src/data/m4_forecasting/Daily-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46dcfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nnknn(X_cases, Y_targets, L, epochs=100, lr=0.01, shared_weights=False):\n",
    "    model = NNKNN(num_features=L, num_cases=X_cases.shape[0], shared_weights=shared_weights)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    \n",
    "    for _epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        # Use the cases themselves as queries for training\n",
    "        y_hat, _, _ = model(X_cases, X_cases, Y_targets)\n",
    "        loss = criterion(y_hat, Y_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def forecast_nnknn(train_row, L=30, H=7, epochs=100, shared_weights=False):\n",
    "    if isinstance(train_row, pd.Series):\n",
    "        train_row = train_row.to_numpy().flatten()\n",
    "\n",
    "    X_cases, Y_targets = build_windows(train_row, L=L, H=H)\n",
    "\n",
    "    X_cases = torch.tensor(X_cases, dtype=torch.float32)\n",
    "    Y_targets = torch.tensor(Y_targets, dtype=torch.float32)\n",
    "    \n",
    "    # train model\n",
    "    model = train_nnknn(X_cases, Y_targets, L=L, epochs=epochs, shared_weights=shared_weights)\n",
    "\n",
    "    # last window as query\n",
    "    query = torch.tensor(train_row[-L:], dtype=torch.float32).unsqueeze(0)\n",
    "  \n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_hat, _, _ = model(query, X_cases, Y_targets)\n",
    "    \n",
    "    return y_hat.squeeze(0).cpu().numpy()  # shape [H]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1fccda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_forecast(train_row, test_row, L=30, H=14):\n",
    "\n",
    "    train_ts = clean_daily_series(train_row)\n",
    "    test_ts = clean_daily_series(test_row)\n",
    "    \n",
    "\n",
    "    # Enforce M4 horizon limit (daily test series have length of 14)\n",
    "    H_eval = min(H, len(test_ts))\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    train_ts_scaled = scaler.fit_transform(\n",
    "        train_ts.to_numpy().reshape(-1, 1)\n",
    "    ).flatten()\n",
    "\n",
    "    y_pred = forecast_nnknn(train_ts_scaled, L=L, H=H_eval)\n",
    "    y_pred = np.atleast_1d(y_pred)\n",
    "\n",
    "    y_pred = scaler.inverse_transform(\n",
    "        y_pred.reshape(-1, 1)\n",
    "    ).flatten()\n",
    "    \n",
    "    y_true = np.atleast_1d(test_ts)\n",
    "\n",
    "    return (\n",
    "        rmse(y_true[:H_eval], y_pred[:H_eval]),\n",
    "        mae(y_true[:H_eval], y_pred[:H_eval]),\n",
    "        smape(y_true[:H_eval], y_pred[:H_eval]),\n",
    "        mase(y_true[:H_eval], y_pred[:H_eval], train_ts, m=7),\n",
    "        directional_accuracy(y_true[:H_eval], y_pred[:H_eval])\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1228b4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating horizon H=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed: 11.5min remaining:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed: 11.7min remaining:   44.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating horizon H=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 11.8min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "python(92720) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(92721) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(92722) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(92723) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(92724) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:  6.2min remaining:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:  6.5min remaining:   24.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating horizon H=14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  6.6min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "python(94261) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(94262) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(94263) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(94264) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  3.5min\n",
      "/Users/willarachelian/anaconda3/envs/data-science/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "python(95098) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(95135) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:  5.6min remaining:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:  5.8min remaining:   22.2s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  5.9min finished\n"
     ]
    }
   ],
   "source": [
    "horizons = [1, 7, 14]\n",
    "L = 30\n",
    "NUM_SERIES = 50\n",
    "\n",
    "daily_train_copy = daily_train.copy()\n",
    "daily_test_copy = daily_test.copy()\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for H in horizons:\n",
    "    print(f\"Evaluating horizon H={H}\")\n",
    "    results = Parallel(n_jobs=-1, backend=\"loky\", verbose=10)(\n",
    "        delayed(evaluate_forecast)(daily_train_copy.iloc[i], daily_test_copy.iloc[i], L=L, H=H)\n",
    "        for i in range(NUM_SERIES)\n",
    "    )\n",
    "    all_results[H] = results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "325a5368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Horizon: 1\n",
      "      Metric      Mean    Median\n",
      "0       RMSE  329.6796  187.0578\n",
      "1        MAE  329.6796  187.0578\n",
      "2  sMAPE (%)   10.1814    5.2177\n",
      "3       MASE    4.7882    1.6645\n",
      "4         DA       NaN       NaN\n",
      "\n",
      "Horizon: 7\n",
      "      Metric      Mean    Median\n",
      "0       RMSE  418.5363  229.9372\n",
      "1        MAE  406.3746  224.1643\n",
      "2  sMAPE (%)   11.8964    6.8392\n",
      "3       MASE    5.3511    2.2247\n",
      "4         DA    0.5433    0.5000\n",
      "\n",
      "Horizon: 14\n",
      "      Metric      Mean    Median\n",
      "0       RMSE  423.0747  213.3350\n",
      "1        MAE  399.0892  205.7850\n",
      "2  sMAPE (%)   11.6774    7.6299\n",
      "3       MASE    5.4933    2.3858\n",
      "4         DA    0.5215    0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willarachelian/Desktop/492 shared/knn-tree_layers-financial-forecasting/experiments/utils.py:93: RuntimeWarning: Mean of empty slice\n",
      "  np.nanmean(das)\n",
      "/Users/willarachelian/Desktop/492 shared/knn-tree_layers-financial-forecasting/experiments/utils.py:100: RuntimeWarning: All-NaN slice encountered\n",
      "  np.nanmedian(das)\n"
     ]
    }
   ],
   "source": [
    "for H, results in all_results.items():\n",
    "    # results: list of tuples per series\n",
    "    rmses, maes, smapes, mases, das = zip(*results)\n",
    "\n",
    "    print(f\"\\nHorizon: {H}\")\n",
    "    print_evaluation_table(rmses, maes, smapes, mases, das)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
